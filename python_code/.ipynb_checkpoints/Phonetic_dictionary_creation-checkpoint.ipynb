{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcgtq-niZLT"
   },
   "source": [
    "'''\n",
    " 08/10/2022\n",
    "\n",
    "This program is intended for creation of **lexicon/phonetic dictionary**.\n",
    "\n",
    " Following are the steps in the program\n",
    "  \n",
    "\n",
    "1.   program take input as set of text files and extract all unique Devanagari word and store it as sorted list of words\n",
    "2.   single or multiple phonetical traciption are generated and dictionary is created and stored as a text file.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devnagari Konkani word to IPA conversion.\n",
    "\n",
    "#setting path of file \n",
    "file_path=\"data\\\\Unique_words.txt\"\n",
    "\n",
    "#read words from file and store it in list\n",
    "# opening the file in read mode\n",
    "#my_file = open(file_path, 'r','utf-8')\n",
    "my_file = open(file_path, 'r',encoding=\"utf-8\")  \n",
    "\n",
    "# reading the file\n",
    "data = my_file.read()\n",
    "  \n",
    "# replacing end of line('/n') with ' ' and\n",
    "# splitting the text it further when ' ' is seen.\n",
    "word_list = data.replace('\\n', ' ').split(\" \")\n",
    "  \n",
    "# printing the data \n",
    "#print(word_list)\n",
    "my_file.close()\n",
    "\n",
    "\n",
    "#dictionary mapping initialisation\n",
    "mapping={'अ' : 'ə', 'आ' : 'a', 'ा' : 'a', \n",
    "         'इ' : 'i', 'ि' : 'i', 'ई' : 'i:', 'ी' : 'i', \n",
    "         'उ' : 'u', 'ु' : 'u', 'ऊ' : 'u:', 'ू' : 'u',\n",
    "         'ए' : 'e', 'े' : 'e', 'ॲ' : 'ɛ', 'ऍ' : 'ɛ', 'ॅ' : 'ɛ', \n",
    "         'ओ' : 'o', 'ो' : 'o', 'ऑ' : 'ɔ', 'ॉ' : 'ɔ',\n",
    "         'ऐ' : 'ɨj', 'ै' : 'ɨj', 'औ' : 'əu', 'ौ' : 'əu',\n",
    "         'ऋ' : 'x', 'ृ' : 'x', 'ॠ' : 'X', 'ॄ' : 'X',\n",
    "         'ऌ' : 'q', 'ॢ' : 'q','ॡ' : 'Q', 'ॣ' : 'Q',\n",
    "         'ऎ' : 'e', 'ॆ' : 'e', 'ऒ' : 'o', 'ॊ' : 'o',\n",
    "         'ँ' : 'M’', 'ं' : '◌̃', 'ः' : 'H',\n",
    "         'क' : 'kə', 'ख' : 'kʰə', 'ग' : 'gə', 'घ' : 'gʱə', 'ङ' : 'ŋə', \n",
    "         'च' : 'tʃə', 'छ' : 'tʃʰə', 'ज' : 'dʒə', 'झ' : 'dʒʱə', 'ञ' : 'ɲə',\n",
    "         'ट' : 'ʈə', 'ठ' : 'ʈʰə', 'ड' : 'ɖə', 'ढ' : 'ɖʰə', 'ण' : 'ɳə', \n",
    "         'त' : 't̪ə', 'थ' : 't̪ʰə', 'द' : 'd̪ə', 'ध' : 'd̪ʰə', 'न' : 'nə', \n",
    "         'प' : 'pə', 'फ' : 'fə', 'ब' : 'bə', 'भ' : 'bʱə', 'म' : 'mə',\n",
    "         'य' : 'jə', 'र' : 'rə', 'ल' : 'lə', 'व' : 'ʋə',\n",
    "         'श' : 'ʃə', 'ष' : 'ʂə', 'स' : 'sə', 'ह' : 'ɦə',\n",
    "         'ळ' : 'ɭə', 'ऴ' : 'Zaə', 'ॐ' : 'omə', '्' : '',\n",
    "         'ऱ':'r','य़':'jə',\n",
    "         '़़':'','ऽ':'','-':''\n",
    "        }\n",
    "\n",
    "#final dictionary file\n",
    "file = open(\"data\\phonetic_dictionary.txt\", \"w\",encoding=\"utf-8\")\n",
    "\n",
    "#giving words from list for phonetic transcription\n",
    "for words in word_list:\n",
    "    #devnagari_word=\"कोंकणी\"\n",
    "    devnagari_word=words\n",
    "    IPA_transcription=\"\"\n",
    "\n",
    "    for i in devnagari_word:\n",
    "        #print(i)\n",
    "        #IPA_transcription+=mapping.get(i)\n",
    "        if (i==\"ं\"):\n",
    "            #last=IPA_transcription[-1]\n",
    "            #IPA_transcription=IPA_transcription[:-1]+mapping.get(i)+last\n",
    "            IPA_transcription+= '\\u0303' #combining nasalisation to phone\n",
    "            #print(\"special case:\",IPA_transcription)\n",
    "            continue\n",
    "        if (i==\"्\"or i == 'ा' or i == 'ि' or i == 'ी' or i == 'ु' \n",
    "            or i == 'ू' or i == 'े' or i == 'ॅ' or i == 'ो' or i == 'ॉ'\n",
    "            or i == 'ै' or i == 'ौ' or i == 'ौ' or i == 'ृ' or i == 'ॄ' or \n",
    "            i == 'ॢ' or i == 'ॣ' or i == 'ॆ' or i == 'ॊ'):\n",
    "        \n",
    "            IPA_transcription=IPA_transcription[:-1]+mapping.get(i)\n",
    "            #print(\"special case:\",IPA_transcription)\n",
    "            continue\n",
    "        if(i=='़'or i=='ऽ' or i=='-'):\n",
    "            continue\n",
    "        if (i=='\\u200d'):# ZERO WIDTH JOINER (‍) for words like तिसर्‍या\n",
    "            continue\n",
    "        # problem with character combination च्च need to sorted\n",
    "        else:\n",
    "            IPA_transcription+=mapping.get(i)\n",
    "    \n",
    "        #print(mapping.get(i))\n",
    "    #print(IPA_transcription)\n",
    "    line=devnagari_word+\" \"+IPA_transcription+\"\\n\"\n",
    "    file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "त\n",
      "ि\n",
      "स\n",
      "र\n",
      "्\n",
      "‍\n",
      "य\n",
     ]
    }
   ],
   "source": [
    "#code for testing valid devnagari character set\n",
    "#devnagari_word=\"उच̵टन उच̵रतना उच̶  उच्चाटन तिसर्‍या\"\n",
    "devnagari_word=\"तिसर्‍या  फुडार्या‍न बच̵न\"\n",

    "#devnagari_word=words\n",
    "IPA_transcription=\"\"\n",
    "\n",
    "#dictionary mapping initialisation\n",
    "mapping={'अ' : 'ə', 'आ' : 'a', 'ा' : 'a', \n",
    "         'इ' : 'i', 'ि' : 'i', 'ई' : 'i:', 'ी' : 'i', \n",
    "         'उ' : 'u', 'ु' : 'u', 'ऊ' : 'u:', 'ू' : 'u',\n",
    "         'ए' : 'e', 'े' : 'e', 'ॲ' : 'ɛ', 'ऍ' : 'ɛ', 'ॅ' : 'ɛ', \n",
    "         'ओ' : 'o', 'ो' : 'o', 'ऑ' : 'ɔ', 'ॉ' : 'ɔ',\n",
    "         'ऐ' : 'ɨj', 'ै' : 'ɨj', 'औ' : 'əu', 'ौ' : 'əu',\n",
    "         'ऋ' : 'x', 'ृ' : 'x', 'ॠ' : 'X', 'ॄ' : 'X',\n",
    "         'ऌ' : 'q', 'ॢ' : 'q','ॡ' : 'Q', 'ॣ' : 'Q',\n",
    "         'ऎ' : 'e', 'ॆ' : 'e', 'ऒ' : 'o', 'ॊ' : 'o',\n",
    "         'ँ' : 'M’', 'ं' : '◌̃', 'ः' : 'H',\n",
    "         'क' : 'kə', 'ख' : 'kʰə', 'ग' : 'gə', 'घ' : 'gʱə', 'ङ' : 'ŋə', \n",
    "         'च' : 'tʃə', 'छ' : 'tʃʰə', 'ज' : 'dʒə', 'झ' : 'dʒʱə', 'ञ' : 'ɲə',\n",
    "         'ट' : 'ʈə', 'ठ' : 'ʈʰə', 'ड' : 'ɖə', 'ढ' : 'ɖʰə', 'ण' : 'ɳə', \n",
    "         'त' : 't̪ə', 'थ' : 't̪ʰə', 'द' : 'd̪ə', 'ध' : 'd̪ʰə', 'न' : 'nə', \n",
    "         'प' : 'pə', 'फ' : 'fə', 'ब' : 'bə', 'भ' : 'bʱə', 'म' : 'mə',\n",
    "         'य' : 'jə', 'र' : 'rə', 'ल' : 'lə', 'व' : 'ʋə',\n",
    "         'श' : 'ʃə', 'ष' : 'ʂə', 'स' : 'sə', 'ह' : 'ɦə',\n",
    "         'ळ' : 'ɭə', 'ऴ' : 'Zaə', 'ॐ' : 'omə', '्' : '',\n",
    "         'ऱ':'r',\n",
    "         '़':'','ऽ':''\n",
    "        }\n",
    "\n",
    "for i in devnagari_word:\n",
    "    print (i)\n",
    "    '''\n",
    "    if (i==\"ं\"):\n",
    "        #last=IPA_transcription[-1]\n",
    "        #IPA_transcription=IPA_transcription[:-1]+mapping.get(i)+last\n",
    "        IPA_transcription+= '\\u0303' #combining nasalisation to phone\n",
    "        #print(\"special case:\",IPA_transcription)\n",
    "    if (i==\"्\"or i == 'ा' or i == 'ि' or i == 'ी' or i == 'ु' \n",
    "        or i == 'ू' or i == 'े' or i == 'ॅ' or i == 'ो' or i == 'ॉ'\n",
    "        or i == 'ै' or i == 'ौ' or i == 'ौ' or i == 'ृ' or i == 'ॄ' or \n",
    "        i == 'ॢ' or i == 'ॣ' or i == 'ॆ' or i == 'ॊ'):\n",
    "        \n",
    "        IPA_transcription=IPA_transcription[:-1]+mapping.get(i)\n",
    "        print(\"special case:\",IPA_transcription)\n",
    "        continue\n",
    "    else:\n",
    "        IPA_transcription+=mapping.get(i)\n",
    "    \n",
    "    print(mapping.get(i))\n",
    "print(IPA_transcription)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1665306670659,
     "user": {
      "displayName": "Hanumant Harichandra Redkar",
      "userId": "04846405555973888391"
     },
     "user_tz": -330
    },
    "id": "FdR74n21jbjV",
    "outputId": "c7e81854-a403-4822-8406-6d119dd6408d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ContemporaryTextFiles/file1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# taking input from file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# from google.colab import drive\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# drive.mount('/content/content/drive')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContemporaryTextFiles/file1.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m myFile:\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m myLine \u001b[38;5;129;01min\u001b[39;00m myFile:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(myLine)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ContemporaryTextFiles/file1.txt'"
     ]
    }
   ],
   "source": [
    "# taking input from file\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/content/drive')\n",
    "\n",
    "with open('ContemporaryTextFiles/file1.txt', 'rt') as myFile:\n",
    "  for myLine in myFile:\n",
    "    print(myLine);\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RJBFGkLLAzHE"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'ContemporaryTextFiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m      7\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContemporaryTextFiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m     10\u001b[0m   count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'ContemporaryTextFiles'"
     ]
    }
   ],
   "source": [
    "# Script to rename files \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/content/drive') \n",
    "# drive.mount('/content/ContemporaryTextFiles/')\n",
    "\n",
    "import os \n",
    "count = 0\n",
    "files = os.listdir('ContemporaryTextFiles')\n",
    "for item in files:\n",
    "  count = count+1\n",
    "print(count)\n",
    "\n",
    "#src = os.listdir('ContemporaryTextFiles')\n",
    "src = os.listdir('ContemporaryTextFiles')[1]\n",
    "# print(src)\n",
    "dir = 'ContemporaryTextFiles/'\n",
    "index = 0\n",
    "for item in files:\n",
    "  while index < count:\n",
    "    src = os.listdir('ContemporaryTextFiles')[index]\n",
    "    # START FILE OPERATION\n",
    "    print(src)\n",
    "    os.rename(dir+src, 'file_'+str(index)+'.txt')\n",
    "    print('Renamed...')\n",
    "    # with open('ContemporaryTextFiles/'+src, 'rt') as myFile:\n",
    "    #   for myLine in myFile:\n",
    "    #     print(myLine);\n",
    "    #     break;\n",
    "    #  START FILE OPERATION\n",
    "    index = index+1\n",
    "\n",
    "\n",
    "\n",
    "# print('Updated Files')\n",
    "# print(os.listdir('ContemporaryTextFiles'))\n",
    "\n",
    "# count = os.listdir('ContemporaryTextFiles').count()\n",
    "# print(count)\n",
    "# os.rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ymY-aJTiBBHL"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'ContemporaryTextFiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m      3\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContemporaryTextFiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      6\u001b[0m   count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'ContemporaryTextFiles'"
     ]
    }
   ],
   "source": [
    "# Script to Uniquely extract unique tokens \n",
    "import os \n",
    "count = 0\n",
    "files = os.listdir('ContemporaryTextFiles')\n",
    "for item in files:\n",
    "  count = count+1\n",
    "print(count)\n",
    "\n",
    "#src = os.listdir('ContemporaryTextFiles')\n",
    "src = os.listdir('ContemporaryTextFiles')[1]\n",
    "# print(src)\n",
    "dir = 'ContemporaryTextFiles/'\n",
    "index = 0\n",
    "for item in files:\n",
    "  while index < count:\n",
    "    src = os.listdir('ContemporaryTextFiles')[index]\n",
    "    # START FILE OPERATION\n",
    "    print(src)\n",
    "    os.rename(dir+src, 'file_'+str(index)+'.txt')\n",
    "    print('Renamed...')\n",
    "    # with open('ContemporaryTextFiles/'+src, 'rt') as myFile:\n",
    "    #   for myLine in myFile:\n",
    "    #     print(myLine);\n",
    "    #     break;\n",
    "    #  START FILE OPERATION\n",
    "    index = index+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1665310917136,
     "user": {
      "displayName": "Hanumant Harichandra Redkar",
      "userId": "04846405555973888391"
     },
     "user_tz": -330
    },
    "id": "EJkDHlayQXQW",
    "outputId": "cdca5777-92cc-4982-8bf5-7ece7942ce55"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ContemporaryTextFiles/data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Program to Extract Unique words from English Text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContemporaryTextFiles/\u001b[39m\u001b[38;5;124m'\u001b[39m;\n\u001b[1;32m----> 3\u001b[0m text_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m text_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#cleaning\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ContemporaryTextFiles/data.txt'"
     ]
    }
   ],
   "source": [
    "# Program to Extract Unique words from English Text\n",
    "dir = 'ContemporaryTextFiles/';\n",
    "text_file = open(dir+'data.txt', 'r')\n",
    "text = text_file.read()\n",
    "\n",
    "#cleaning\n",
    "text = text.lower()\n",
    "words = text.split()\n",
    "words = [word.strip('.,!;()[]') for word in words]\n",
    "words = [word.replace(\"'s\", '') for word in words]\n",
    "\n",
    "#finding unique\n",
    "unique = []\n",
    "for word in words:\n",
    "    if word not in unique:\n",
    "        unique.append(word)\n",
    "\n",
    "#sort\n",
    "unique.sort()\n",
    "\n",
    "#print\n",
    "print(unique)\n",
    "# WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1665311142602,
     "user": {
      "displayName": "Hanumant Harichandra Redkar",
      "userId": "04846405555973888391"
     },
     "user_tz": -330
    },
    "id": "gOgC4Ge2Q_0F",
    "outputId": "51c0e0ab-baf4-49be-967c-94a0359972fe"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'InputFiles/file_0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Program to Extract Unique words from Konkani Text\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputFiles/\u001b[39m\u001b[38;5;124m'\u001b[39m;\n\u001b[1;32m----> 3\u001b[0m text_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_0.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m text_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#cleaning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# text = text.lower()\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'InputFiles/file_0.txt'"
     ]
    }
   ],
   "source": [
    "# Program to Extract Unique words from Konkani Text\n",
    "dir = 'InputFiles/';\n",
    "text_file = open(dir+'file_0.txt', 'r')\n",
    "text = text_file.read()\n",
    "\n",
    "#cleaning\n",
    "# text = text.lower()\n",
    "words = text.split()\n",
    "words = [word.strip('.,!;()[]') for word in words]\n",
    "words = [word.replace(\"'s\", '') for word in words]\n",
    "\n",
    "#finding unique\n",
    "unique = []\n",
    "for word in words:\n",
    "    if word not in unique:\n",
    "        unique.append(word)\n",
    "\n",
    "#sort\n",
    "unique.sort()\n",
    "\n",
    "#print\n",
    "print(unique)\n",
    "# WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2838,
     "status": "ok",
     "timestamp": 1665321545349,
     "user": {
      "displayName": "Hanumant Harichandra Redkar",
      "userId": "04846405555973888391"
     },
     "user_tz": -330
    },
    "id": "rhiIy_SGR23X",
    "outputId": "c33835c3-0be0-4bb3-9009-cf47c4d524c3",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Input/SortedToBeSorted.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(os.getcwd())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# from google.colab import drive\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# text_file = open(dir+'T1-0010.txt', 'r')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# text = text_file.read()\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput/SortedToBeSorted.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m myFile:\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m myFile:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# print(item)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     text \u001b[38;5;241m=\u001b[39m item;\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Input/SortedToBeSorted.txt'"
     ]
    }
   ],
   "source": [
    "# Program to Extract Unique words from Konkani Text\n",
    "import os\n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/') \n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "# os.system('cd ')\n",
    "\n",
    "# dir = 'data/';\n",
    "# text_file = open(dir+'T1-0010.txt', 'r')\n",
    "# text = text_file.read()\n",
    "\n",
    "with open('Input/SortedToBeSorted.txt', 'rt') as myFile:\n",
    "  for item in myFile:\n",
    "    # print(item)\n",
    "    text = item;\n",
    "\n",
    "    #cleaning\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [word.strip('.,!;()[]') for word in words]\n",
    "    words = [word.replace(\"'s\", '') for word in words]\n",
    "\n",
    "\n",
    "    #finding unique\n",
    "    unique = []\n",
    "    for word in words:\n",
    "        if word not in unique:\n",
    "            unique.append(word)\n",
    "\n",
    "    #sort\n",
    "    unique.sort()\n",
    "\n",
    "    #print\n",
    "    print(unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devnagri,Phonetic Transcription\n",
      "\n",
      "अ,a\n",
      "\n",
      "अ,a\n",
      "\n",
      "आ,A\n",
      "\n",
      "ा,A\n",
      "\n",
      "इ,i\n",
      "\n",
      "ि,i\n",
      "\n",
      "ई,I\n",
      "\n",
      "ी,I\n",
      "\n",
      "उ,u\n",
      "\n",
      "ु,u\n",
      "\n",
      "ऊ,U\n",
      "\n",
      "ू,U\n",
      "\n",
      "ए,E\n",
      "\n",
      "े,E\n",
      "\n",
      "ॲ,eo\n",
      "\n",
      "ऍ,eo\n",
      "\n",
      "ॅ,eo\n",
      "\n",
      "ओ,O\n",
      "\n",
      "ो,O\n",
      "\n",
      "ऑ,ao\n",
      "\n",
      "ॉ,ao\n",
      "\n",
      "ऐ,ai\n",
      "\n",
      "ै,ai\n",
      "\n",
      "औ,au\n",
      "\n",
      "ौ,au\n",
      "\n",
      "ऋ,x\n",
      "\n",
      "ृ,x\n",
      "\n",
      "ॠ,X\n",
      "\n",
      "ॄ,X\n",
      "\n",
      "ऌ,q\n",
      "\n",
      "ॢ,q\n",
      "\n",
      "ॡ,Q\n",
      "\n",
      "ॣ,Q\n",
      "\n",
      "ऎ,e\n",
      "\n",
      "ॆ,e\n",
      "\n",
      "ऒ,o\n",
      "\n",
      "ॊ,o\n",
      "\n",
      "ँ,M’\n",
      "\n",
      "ं,M\n",
      "\n",
      "ः,H\n",
      "\n",
      "क,ka\n",
      "\n",
      "ख,kha\n",
      "\n",
      "ग,ga\n",
      "\n",
      "घ,gha\n",
      "\n",
      "ङ,ng'a\n",
      "\n",
      "च,ca\n",
      "\n",
      "च,ca\n",
      "\n",
      "छ,cha\n",
      "\n",
      "ज,ja\n",
      "\n",
      "ज,ja\n",
      "\n",
      "झ,jha\n",
      "\n",
      "झ,jha\n",
      "\n",
      "ञ,nj'a\n",
      "\n",
      "ट,Ta\n",
      "\n",
      "ठ,Tha\n",
      "\n",
      "ड,Da\n",
      "\n",
      "ढ,Dha\n",
      "\n",
      "ण,Na\n",
      "\n",
      "त,ta\n",
      "\n",
      "थ,tha\n",
      "\n",
      "द,da\n",
      "\n",
      "ध,dha\n",
      "\n",
      "न,na\n",
      "\n",
      "प,pa\n",
      "\n",
      "फ*,pha\n",
      "\n",
      "ब,ba\n",
      "\n",
      "भ,bha\n",
      "\n",
      "म,ma\n",
      "\n",
      "य,ya\n",
      "\n",
      "र,ra\n",
      "\n",
      "ल,la\n",
      "\n",
      "व,va\n",
      "\n",
      "श,sha\n",
      "\n",
      "ष*,Sa\n",
      "\n",
      "स,sa\n",
      "\n",
      "ह,ha\n",
      "\n",
      "ळ,La\n",
      "\n",
      "ऴ,Za\n",
      "\n",
      "क्ष*,ks\n",
      "\n",
      "ज्ञ*,dn\n",
      "\n",
      "ॐ,om\n",
      "\n",
      "श्री,shree\n",
      "\n",
      "०,0\n",
      "\n",
      "१,1\n",
      "\n",
      "२,2\n",
      "\n",
      "३,3\n",
      "\n",
      "४,4\n",
      "\n",
      "५,5\n",
      "\n",
      "६,6\n",
      "\n",
      "७,7\n",
      "\n",
      "८,8\n",
      "\n",
      "९,9\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "#work in progress\n",
    "# code to take words in konkani and converts it to phonetic represantation\n",
    "path=\"CleanedData/\"\n",
    "file_name=\"words.csv\"\n",
    "\n",
    "File_path=path+file_name\n",
    "\n",
    "#code for Konkani devnagri charcter to IPA mapping\n",
    "\"\"\"\n",
    "This code will use devnagri phonetic transcription rule \n",
    "from excel/csv file and creates a dictionary mappings\n",
    "\"\"\"\n",
    "f=open(\"data/phonetic_mapping_data/devnagari_mapping.csv\",\"r\",encoding='utf-8')\n",
    "for lines in f:\n",
    "    print(lines)\n",
    "\n",
    "#code for word to phone mapping\n",
    "#with open(File_path, 'rb') as myFile:\n",
    "\n",
    "\"\"\"\n",
    "with open(File_path, 'r',encoding='utf-8') as myFile:\n",
    "    for words in myFile:\n",
    "        for characters in words:\n",
    "            print(characters,\" \")\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
